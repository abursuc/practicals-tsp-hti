{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03_dogscats_linear_classifier_dldiy_hti_colab.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "HMZBihNguTQr"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:pytorch]",
      "language": "python",
      "name": "conda-env-pytorch-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abursuc/practicals_hti_2019/blob/master/03_dogscats_linear_classifier_dldiy_hti_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PKrEJX4IuTN3"
      },
      "source": [
        "# Training a simple neural network from VGG16 features\n",
        "\n",
        "The last layer of Vgg16 outputs a vector of 1000 categories, because that is the number of categories the competition asked for. Of these categories, some of them certainly correspond to cats and dogs, but at a much more granular level (specific breeds).\n",
        "\n",
        "We will simply add a Dense layer on top of the imagenet layer, and train the model to map the imagenet classifications of input images of cats and dogs to cat and dog labels.\n",
        "\n",
        "Note that this is not what we have been doing in the very first lecture!\n",
        "\n",
        "Have a look at [CS231n: Linear Classification](http://cs231n.github.io/linear-classify/) for more precisions and especially to [CS231n: Softmax classifier](http://cs231n.github.io/linear-classify/#softmax)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KyxtNaA0uTN5"
      },
      "source": [
        "## 1. Preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acOo9KHRugOi",
        "colab": {}
      },
      "source": [
        "!pip install -U bcolz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhrVSSiK2H--",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJHZTL49rPvE",
        "colab_type": "text"
      },
      "source": [
        "In case the _Dogs and Cats_ data that we have used in the previous lecture is no longer on your drive you will nee to download it again as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9do56xnrsF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir data\n",
        "%cd /content/data/\n",
        "!wget http://files.fast.ai/data/dogscats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhPscwUdr0Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip dogscats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PG0R8S_auTN5",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import bcolz\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lnsjg6XguTOB",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFkzb8nb4BD3",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbiLBOHcuTOA"
      },
      "source": [
        "We will first compute the features for all images as the output of the VGG16 network. Unlike previous TP where we were precomputing convolutional features with the goal of fine-tuning the top _fully-connected layers_, here we will take the final output of VGG16, _i.e._ $1000d$ vectors, and use it on a different setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6lp57KjUuTN9",
        "colab": {}
      },
      "source": [
        "# specific functions for loading bcolz files in which the current dataset\n",
        "# is saved\n",
        "def save_array(fname, arr):\n",
        "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
        "    c.flush()\n",
        "\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr6JX6lf33S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "vgg_format = transforms.Compose([\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UnSiC7vPuTOG",
        "colab": {}
      },
      "source": [
        "#where you store your features\n",
        "data_dir = '/content/data/dogscats'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlWdABC14O-5",
        "colab_type": "text"
      },
      "source": [
        "`datasets` is a class of the torchvision package (see `torchvision.datasets`) and deals with data loading. It integrates a multi-threaded loader that fetches images from the disk, groups them in mini-batches and serves them continously to the GPU right after each forward/backward pass through the network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-hTe5dV4MvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "vgg_format = transforms.Compose([\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnrfCQNf4Skz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)\n",
        "         for x in ['train', 'valid']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga97w4gt4di_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dset_sizes = {x: len(dsets[x]) for x in ['train', 'valid']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz2cOJ4T4qsr",
        "colab_type": "text"
      },
      "source": [
        "Depending on the memory of your GPU you can adjust the `batch_size` to be lower or higher."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSCrM6N4pwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "# batch_size = 4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-_wpYcC44p8",
        "colab_type": "text"
      },
      "source": [
        "Initialize data loader that will fetch images from disk using num_workers parallel threads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmefq8fe44G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                               shuffle=False, num_workers=4)\n",
        "                for x in ['train', 'valid']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN-ut2Bm5EYo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Instantiate VGG16 model pretrained on ImageNet from the `torchvision` model Zoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlwJfQI_5HqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg = models.vgg16(pretrained=True)\n",
        "model_vgg.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs0Q5BC55ORy",
        "colab_type": "text"
      },
      "source": [
        "By default all the modules are initialized to train mode (`self.training = True`). Also be aware that some layers have different behavior during train/and evaluation (like `BatchNorm`, `Dropout`) so setting it matters.\n",
        "\n",
        "Also as a rule of thumb for programming in general, try to explicitly state your intent and set `model.train()` and `model.eval()` when necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8bfDFFx5X6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsv7eGzJ5jMR",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Cq5TXp5oJy",
        "colab_type": "text"
      },
      "source": [
        "Function for extracting and storing CNN features, i.e. the ouput of VGG16 model in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMeP1kFO5mUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prefeat(dataset):\n",
        "    features = []\n",
        "    labels_list = []\n",
        "    for data in dataset:\n",
        "        inputs,labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device) \n",
        "        \n",
        "        x = model_vgg(inputs)\n",
        "        features.extend(x.data.cpu().numpy())\n",
        "        labels_list.extend(labels.data.cpu().numpy())\n",
        "    features = np.concatenate([[feat] for feat in features])\n",
        "    return (features,labels_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ngOgaAw7biu",
        "colab_type": "text"
      },
      "source": [
        "This should take about 2 minutes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0bmLuIC6CP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "feat_train,labels_train = prefeat(dset_loaders['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxVA47sz6aai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2I9RpIa6y8t",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Loading and resizing the images every time we want to use them isn't necessary - instead we should save the processed arrays. By far the fastest way to save and load numpy arrays is using bcolz. This also compresses the arrays, so we save disk space. Here are the functions we'll use to save and load using bcolz (already loaded above...)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm-kwMn161Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/data/dogscats/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbCMMJvC65Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir vgg16_1k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlQEuzzI66w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_array(os.path.join(data_dir,'vgg16_1k','feat_1k_train.bc'),feat_train)\n",
        "save_array(os.path.join(data_dir,'vgg16_1k','labels_1k_train.bc'),labels_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O6Np5KW7T8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "feat_val,labels_val = prefeat(dset_loaders['valid'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuoT6S_Y7kl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZgwEj7C7pNz",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9lRnEec7oly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_array(os.path.join(data_dir,'vgg16_1k','feat_1k_val.bc'),feat_val)\n",
        "save_array(os.path.join(data_dir,'vgg16_1k','labels_1k_val.bc'),lbs_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OAwRNH_72mH",
        "colab_type": "text"
      },
      "source": [
        "### Optional: uploading precomputed features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W-Ye1Cc775I",
        "colab_type": "text"
      },
      "source": [
        "This section will allow you to store the precomputed features on your Google drive for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFeSM6g07xMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/data/dogscats/\n",
        "!zip -r vgg16_1k vgg16_1k/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOaPKzYD8BUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMU-VaFF8Cf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload = drive.CreateFile({'title': 'vgg16_drive.zip'})\n",
        "upload.SetContentFile('vgg16.zip')\n",
        "upload.Upload()\n",
        "print('Uploaded file with ID {}'.format(upload.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uGbUxhpJuTPC"
      },
      "source": [
        "## 3. Linear model for VGG16 features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmfZSTJluTPC"
      },
      "source": [
        "We are now ready to define our linear model.\n",
        "\n",
        "For more details about the [cross entropy cost function](http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sq09hBt6uTO_",
        "colab": {}
      },
      "source": [
        "feat_train = load_array(os.path.join(data_dir,'vgg16_1k','feat_1k_train.bc'))\n",
        "labels_train = load_array(os.path.join(data_dir,'vgg16_1k','labels_1k_train.bc'))\n",
        "feat_val = load_array(os.path.join(data_dir,'vgg16_1k','feat_1k_val.bc'))\n",
        "labels_val = load_array(os.path.join(data_dir,'vgg16_1k','labels_1k_val.bc'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s0V9GnE2uTPC",
        "colab": {}
      },
      "source": [
        "lm = torch.nn.Sequential(\n",
        "    torch.nn.Linear(1000, 2),\n",
        "    torch.nn.LogSoftmax(dim = 1)\n",
        ")\n",
        "loss_fn = torch.nn.NLLLoss(reduction='sum')\n",
        "\n",
        "lm = lm.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wo1UF3fKuTPF"
      },
      "source": [
        "Since our features are currently stacked in a `numpy ndarray`, we need to create a dataset of tensors and then a dataloader.\n",
        "\n",
        "For the dataset, you can use `torch.from_numpy` and `TensorDataset`\n",
        "\n",
        "For the dataloader, you should use `torch.utils.data.DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnjzGy9JuTPF",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataset = # your code\n",
        "test_dataset = # your code\n",
        "train_loader = torch.utils.data.DataLoader(#your code here)\n",
        "test_loader = torch.utils.data.DataLoader(#your code here)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5psdVrkfuTPJ"
      },
      "source": [
        "### 2.1 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJl3OZVluTPJ"
      },
      "source": [
        "We define next a holistic training function (```train_model```) that will:\n",
        "- run for a pre-defined number of epochs/iterations\n",
        "- fetch training samples randomly during each epoch(all samples are used during an epoch)\n",
        "- pass samples through network, compute error, gradients and updates network parameters\n",
        "- keep and print training statistics: training loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WqsjAHC5uTPJ",
        "colab": {}
      },
      "source": [
        "def train_model(model,size,data_loader=None,epochs=1,optimizer=None, loss_fn=None, batch_size=128):\n",
        "    model.train()\n",
        "    num_batches = int(size/batch_size)\n",
        "    loss_t = np.zeros(epochs)\n",
        "    acc_t = np.zeros(epochs)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for ii, (inputs,classes) in tqdm(enumerate(data_loader), total=num_batches):\n",
        "                            \n",
        "            #\n",
        "            # your code\n",
        "            #\n",
        "            running_loss += # your code\n",
        "            running_corrects += # your code\n",
        "            \n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.data.item() / size\n",
        "        \n",
        "        loss_t[epoch] = epoch_loss\n",
        "        acc_t[epoch] = epoch_acc\n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "    return loss_t, acc_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMS2nGQzz_uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model,size,data_loader=None,epochs=1,optimizer=None, loss_fn=None, batch_size=128):\n",
        "    model.train()\n",
        "    num_batches = int(size/batch_size)\n",
        "\n",
        "    loss_t = np.zeros(epochs)\n",
        "    acc_t = np.zeros(epochs)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for ii, (inputs,classes) in tqdm(enumerate(data_loader), total=num_batches):\n",
        "        \n",
        "            inputs = inputs.to(device)\n",
        "            classes = classes.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs,classes)           \n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == classes.data)\n",
        "            \n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.data.item() / size\n",
        "        \n",
        "        loss_t[epoch] = epoch_loss\n",
        "        acc_t[epoch] = epoch_acc\n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "    return loss_t, acc_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sx_C-tbMuTPM"
      },
      "source": [
        "We set our hyperparameters:\n",
        "- learning rate\n",
        "- optimizer to be used for gradient descent, here SGD (Stochastic Gradient Descent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AYnppJ8DuTPN",
        "colab": {}
      },
      "source": [
        "learning_rate = 1e-4\n",
        "optimizer_lm = torch.optim.SGD(lm.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBhHimuVkgDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dset_sizes = {'train': 23000, 'valid': 2000}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hJpimXuLuTPR"
      },
      "source": [
        "We train our model for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFsn7n0yuTPR",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "loss1, acc1 = train_model(model=lm,size=dset_sizes['train'],data_loader = train_loader, epochs=100,optimizer=optimizer_lm, loss_fn=loss_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r-c_SKJHuTPW"
      },
      "source": [
        "We plot the evolution of the training loss across epochs. \n",
        "\n",
        "Ideally is should have a steep descent in the first epochs, then decrease smoothly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4gBydZyyuTPY",
        "colab": {}
      },
      "source": [
        "plt.plot(loss1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JlA0t6bnuTPc"
      },
      "source": [
        "We plot the evolution of the accuracy of our model on the training data. The behavior resembles globally to the one of the loss: big improvement at the beginning, then smaller improvements as training advances.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQCfalL8uTPd",
        "colab": {}
      },
      "source": [
        "plt.plot(acc1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8wbmWXMnuTPf"
      },
      "source": [
        "The __loss__ helps the network to learn and update the parameters according to the criterion that we give to the network.\n",
        "\n",
        "The __accuracy__ on the other hand is a performance metric for the task for which we want to use the network for. In many cases the accuracy cannot be integrated as a loss/criterion function, so we need to identify or design loss functions that will guide the model towards the behavior we wish to have for our task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LUhPRq5tuTPf"
      },
      "source": [
        "Next we let the model train for 100 additional epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LCx-Et3NuTPh",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "loss2, acc2 = train_model(model=lm,size=dset_sizes['train'],data_loader =train_loader ,epochs=100,optimizer=optimizer_lm, loss_fn=loss_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KAWCyfpouTPj"
      },
      "source": [
        "Again we plot the loss and accuracy for the current training interval: _epochs[100:200]_.\n",
        "What changes do you notice? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnll44NguTPj",
        "colab": {}
      },
      "source": [
        "plt.plot(loss2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TRPiQRqxuTPm",
        "colab": {}
      },
      "source": [
        "plt.plot(acc2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MQdbyFBSuTPr"
      },
      "source": [
        "We train the model train for 100 more epochs and plot the evolution of our training indicators. \n",
        "How are they evolving comparing to the previous runs?\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acdwL1zauTPs",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "loss3, acc3 = train_model(model=lm,size=dset_sizes['train'],data_loader =train_loader ,epochs=100,optimizer=optimizer_lm, loss_fn=loss_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Rc5WuaPuTPw",
        "colab": {}
      },
      "source": [
        "plt.plot(loss3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jfEuKrkmuTP2",
        "colab": {}
      },
      "source": [
        "plt.plot(acc3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S7CaET8muTP7"
      },
      "source": [
        "### 2.2 Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v452HrVIuTP8"
      },
      "source": [
        "We define next a holistic test function (```test_model```) that will:\n",
        "- fetch test samples\n",
        "- pass samples through network, compute error, accuracy and predictions\n",
        "- keep and print test statistics: test loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oaENq9k1uTP9",
        "colab": {}
      },
      "source": [
        "def test_model(model,size,data_loader=None, batch_size=128):\n",
        "    model.eval()\n",
        "    num_batches = int(size/batch_size)\n",
        "    predictions = np.zeros(size)\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    count = 0 \n",
        "    for ii, (inputs,classes) in tqdm(enumerate(data_loader), total=num_batches):\n",
        "        #\n",
        "        # your code\n",
        "        #\n",
        "        count +=1\n",
        "        \n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.data.item() / size))\n",
        "    return predictions, running_loss / size, running_corrects.data.item() / size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y02ql1rHuTQA"
      },
      "source": [
        "We evaluate on the test data a snapshot of our model at _epoch #300_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BIRhbtPFuTQC",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "preds, loss_val, acc_val = test_model(model=lm,size=dset_sizes['valid'],data_loader=test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9xYPDhdNuTQG",
        "colab": {}
      },
      "source": [
        "loss_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S-4W062ouTQI"
      },
      "source": [
        "## 3. Quantitative analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sy4ZTZHWuTQK"
      },
      "source": [
        "We concatenate the training losses across the 300 training epochs and plot them along with the loss on the test data using a snapshot of our model at epoch #300.\n",
        "\n",
        "What do you notice? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QtykLETguTQK",
        "colab": {}
      },
      "source": [
        "plt.plot(np.concatenate((loss1, loss2, loss3)))\n",
        "plt.plot([loss_val]*300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KMKOQuOvuTQP"
      },
      "source": [
        "We illustrate a similar plot for the training loss values at _epochs[200:300]_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wofAeNVQuTQP",
        "colab": {}
      },
      "source": [
        "plt.plot(loss3)\n",
        "plt.plot([loss_val]*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jHQ95XxhuTQW"
      },
      "source": [
        "We now illustrate the aggregated training accuracies on epochs[0:300] along with the test accuracy for the model at epoch #300."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wzwKaVAPuTQX",
        "colab": {}
      },
      "source": [
        "plt.plot(np.concatenate((acc1, acc2, acc3)))\n",
        "plt.plot([acc_val]*300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MDHMaNPquTQZ"
      },
      "source": [
        "We train our model for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfqfeVsuuTQc",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "loss4, acc4 = train_model(model=lm,size=dset_sizes['train'],data_loader =train_loader ,epochs=1000,optimizer=optimizer_lm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8g4NOeCPuTQe"
      },
      "source": [
        "We test the model snapshot at _epoch #1300_ and keep its statiscs and performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6kGzqTgcuTQf",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "preds2, conf2, loss_val2, acc_val2 = (test_model(model=lm,size=dset_sizes['valid'],feat=feat_val,labels=lbs_val,batch_size=2000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ma5_9t_BuTQh"
      },
      "source": [
        "We aggregate train loss values at _epochs[300:1300]_ and test loss at _epochs[300]_ and _epochs[1300]_.\n",
        "Do you notice a trend?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "njq90A-7uTQh",
        "colab": {}
      },
      "source": [
        "plt.plot(np.concatenate((loss3,loss4)))\n",
        "plt.plot(np.concatenate(([loss_val]*100,[loss_val2]*1000)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "biVd0Eicb66Y"
      },
      "source": [
        "A similar plot for the accuracy values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fuAt-2gruTQm",
        "colab": {}
      },
      "source": [
        "plt.plot(np.concatenate((acc1, acc2, acc3, acc4)))\n",
        "plt.plot(np.concatenate(([acc_val]*300,[acc_val2]*1000)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfLa3D9WkgE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HMZBihNguTQr"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "What is happening? \n",
        "\n",
        "Make better plots on which we see the evolution of the loss/accuracy on both the training and validation sets as a function of the number of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gdDueKxUuTQs"
      },
      "source": [
        "## 4. Viewing model prediction (qualitative analysis)\n",
        "\n",
        "The most important metrics for us to look at are for the validation set, since we want to check for over-fitting.\n",
        "\n",
        "With our first model we should try to overfit before we start worrying about how to handle that - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques after the 2 weeks break...)\n",
        "\n",
        "\n",
        "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
        "\n",
        "   1. A few correct labels at random\n",
        "   2. A few incorrect labels at random\n",
        "   3. The most correct labels of each class (ie those with highest probability that are correct)\n",
        "   4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
        "   5. The most uncertain labels (ie those with probability closest to 0.5).\n",
        "\n",
        "In general, these are particularly useful for debugging problems in the model. Since our model is very simple, there may not be too much to learn at this stage..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2zlK4iJ2uTQs",
        "colab": {}
      },
      "source": [
        "# Number of images to view for each visualization task\n",
        "n_view = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BGmBImB7uTQv"
      },
      "source": [
        "Selecting correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i7PM-ENHuTQx",
        "colab": {}
      },
      "source": [
        "correct = np.where(preds==lbs_val)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BeafrtLZuTQz",
        "colab": {}
      },
      "source": [
        "from numpy.random import random, permutation\n",
        "idx = permutation(correct)[:n_view]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "csd3SW2FuTQ2",
        "colab": {}
      },
      "source": [
        "idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-vni-AQuTQ5",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "#   Imshow for Tensor.\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "vgg_format = transforms.Compose([\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)\n",
        "         for x in ['train', 'valid']}\n",
        "\n",
        "dataset_correct = torch.utils.data.DataLoader([dsets['valid'][x] for x in idx],batch_size = n_view,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GVQ9iM5buTQ8",
        "colab": {}
      },
      "source": [
        "for data in dataset_correct:\n",
        "    inputs_cor,labels_cor = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7mdvWiSPuTQ9",
        "colab": {}
      },
      "source": [
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs_cor)\n",
        "\n",
        "imshow(out, title=[x for x in labels_cor])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tefNitxUuTRA",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, display\n",
        "for x in idx:\n",
        "    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a-iCNKZSuTRB"
      },
      "source": [
        "Selecting incorrect predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VxmVjAI1uTRC",
        "colab": {}
      },
      "source": [
        "incorrect = np.where(preds!=lbs_val)[0]\n",
        "for x in permutation(incorrect)[:n_view]:\n",
        "    print(dsets['valid'].imgs[x][1])\n",
        "    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cJX3_d_2uTRF",
        "colab": {}
      },
      "source": [
        "#3. The images we most confident were cats, and are actually cats\n",
        "correct_cats = np.where((preds==0) & (preds==lbs_val))[0]\n",
        "most_correct_cats = np.argsort(conf[correct_cats,1])[:n_view]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1rcEbuNUuTRH",
        "colab": {}
      },
      "source": [
        "for x in most_correct_cats:\n",
        "    display(Image(filename=dsets['valid'].imgs[correct_cats[x]][0], retina=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Y8RCsajuTRL",
        "colab": {}
      },
      "source": [
        "#3. The images we most confident were dogs, and are actually dogs\n",
        "correct_dogs = np.where((preds==1) & (preds==lbs_val))[0]\n",
        "most_correct_dogs = np.argsort(conf[correct_dogs,0])[:n_view]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FgcCh_deuTRN",
        "colab": {}
      },
      "source": [
        "for x in most_correct_dogs:\n",
        "    display(Image(filename=dsets['valid'].imgs[correct_dogs[x]][0], retina=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ShVf7O_uTRP"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "1. As seen in the first lecture, the last layer of Vgg16 is simply a dense layer that outputs 1000 elements. Therefore, it seems somewhat unreasonable to stack a dense layer meant to find cats and dogs on top of one that's meant to find imagenet categories, in that we're limiting the information available to us by first coercing the neural network to classify to imagenet before cats and dogs... Instead, do finetuning, _i.e._ remove that last layer and add on a new layer for cats and dogs. Compare to what we did in the first lecture.\n",
        "\n",
        "\n",
        "2. Try out a different network other than VGG16 from the `torchvision` model zoo, _e.g._ ResNet34, ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FRdJVGg_uTRQ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}